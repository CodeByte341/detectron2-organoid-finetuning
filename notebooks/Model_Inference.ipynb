{"cells":[{"cell_type":"markdown","metadata":{"id":"reMeagk2iYIt"},"source":["# Detectron2 Inference - Organoid Detection with IoU Evaluation\n","\n","This notebook demonstrates using a trained Detectron2 model to:\n","1. Detect organoids in microscopy images\n","2. Evaluate predictions against ground truth masks using IoU metric\n","3. Export results with visualizations and IoU scores\n","\n","**Prerequisites:** A trained Detectron2 model (from the training notebook)"]},{"cell_type":"markdown","metadata":{"id":"2AU7TuIPiYIt"},"source":["## 1. Installation and Setup"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"krVbHjIqiYIu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1770564379172,"user_tz":-60,"elapsed":25489,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}},"outputId":"c99744ad-3edf-429c-b329-51083a680dfb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyyaml==5.1\n","  Downloading PyYAML-5.1.tar.gz (274 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/274.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m274.2/274.2 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n","\n","\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n","\u001b[1;36mhint\u001b[0m: See above for details.\n","Cloning into 'detectron2'...\n","remote: Enumerating objects: 15943, done.\u001b[K\n","remote: Counting objects: 100% (13/13), done.\u001b[K\n","remote: Compressing objects: 100% (10/10), done.\u001b[K\n","remote: Total 15943 (delta 4), reused 3 (delta 3), pack-reused 15930 (from 2)\u001b[K\n","Receiving objects: 100% (15943/15943), 6.70 MiB | 12.20 MiB/s, done.\n","Resolving deltas: 100% (11336/11336), done.\n","Ignoring dataclasses: markers 'python_version < \"3.7\"' don't match your environment\n","Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.12/dist-packages (11.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n","Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.12/dist-packages (2.0.11)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (3.3.0)\n","Collecting yacs>=0.1.8\n","  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (3.1.2)\n","Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.12/dist-packages (4.67.2)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.12/dist-packages (2.19.0)\n","Collecting fvcore<0.1.6,>=0.1.5\n","  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting iopath<0.1.10,>=0.1.7\n","  Downloading iopath-0.1.9-py3-none-any.whl.metadata (370 bytes)\n","Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.12/dist-packages (2.3.0)\n","Collecting hydra-core>=1.1\n","  Downloading hydra_core-1.3.2-py3-none-any.whl.metadata (5.5 kB)\n","Collecting black\n","  Downloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (88 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.9/88.9 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (26.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.0.2)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.2)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from yacs>=0.1.8) (6.0.3)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.4.0)\n","Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.76.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.10.1)\n","Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (5.29.5)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (75.2.0)\n","Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (1.17.0)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard) (3.1.5)\n","Collecting portalocker (from iopath<0.1.10,>=0.1.7)\n","  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.12/dist-packages (from omegaconf<2.4,>=2.1) (4.9.3)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from black) (8.3.1)\n","Collecting mypy-extensions>=0.4.3 (from black)\n","  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n","Collecting pathspec>=1.0.0 (from black)\n","  Downloading pathspec-1.0.4-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.12/dist-packages (from black) (4.5.1)\n","Collecting pytokens>=0.3.0 (from black)\n","  Downloading pytokens-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n","Requirement already satisfied: typing-extensions~=4.12 in /usr/local/lib/python3.12/dist-packages (from grpcio>=1.48.2->tensorboard) (4.15.0)\n","Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard) (3.0.3)\n","Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n","Downloading iopath-0.1.9-py3-none-any.whl (27 kB)\n","Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading black-26.1.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n","Downloading pathspec-1.0.4-py3-none-any.whl (55 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.2/55.2 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pytokens-0.4.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (269 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.8/269.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n","Building wheels for collected packages: fvcore\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=680b4de5db5d61975819680d9c2e052236fdbf2df66b2e686d4a46833965ab76\n","  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n","Successfully built fvcore\n","Installing collected packages: yacs, pytokens, portalocker, pathspec, mypy-extensions, iopath, hydra-core, black, fvcore\n","Successfully installed black-26.1.0 fvcore-0.1.5.post20221221 hydra-core-1.3.2 iopath-0.1.9 mypy-extensions-1.1.0 pathspec-1.0.4 portalocker-3.2.0 pytokens-0.4.1 yacs-0.1.8\n"]}],"source":["# Install dependencies\n","!python -m pip install pyyaml==5.1\n","\n","# Import standard libraries\n","import sys\n","import os\n","import distutils.core\n","import torch\n","import numpy as np\n","import cv2\n","import pandas as pd\n","from tqdm import tqdm\n","from PIL import Image\n","from google.colab.patches import cv2_imshow\n","\n","# Install Detectron2\n","!git clone 'https://github.com/facebookresearch/detectron2'\n","dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","sys.path.insert(0, os.path.abspath('./detectron2'))\n","\n","# Import Detectron2 components\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DlAT-rsgiYIu","executionInfo":{"status":"ok","timestamp":1770565110403,"user_tz":-60,"elapsed":4658,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}},"outputId":"30cd8ca8-f646-4539-a141-48c3c45321c1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","metadata":{"id":"LFyT2nioiYIv"},"source":["## 2. Load Trained Model"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"0OnU_VxriYIv","executionInfo":{"status":"ok","timestamp":1770565133110,"user_tz":-60,"elapsed":22700,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}}},"outputs":[],"source":["# Copy trained model from Google Drive\n","!cp -r \"/content/drive/My Drive/Detectron2_Organoid_FineTuning/02_Model\" /content"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IRg6JJ8HiYIv","executionInfo":{"status":"ok","timestamp":1770565134190,"user_tz":-60,"elapsed":1083,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}},"outputId":"f2a424a3-a268-4599-90a5-d718b172d00b"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Model loaded successfully\n"]}],"source":["# Configure model for inference\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","\n","# Dataset configuration\n","cfg.DATASETS.TRAIN = (\"organoid_train\",)\n","cfg.DATASETS.TEST = ()\n","\n","# Model configuration\n","cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1  # Single class: organoid\n","\n","# Load trained weights\n","cfg.MODEL.WEIGHTS = os.path.join(\"/content/02_Model\", \"model_final.pth\")\n","\n","# Inference threshold\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n","\n","# Create predictor\n","predictor = DefaultPredictor(cfg)\n","\n","print(\"✓ Model loaded successfully\")"]},{"cell_type":"markdown","metadata":{"id":"7fjo-hlciYIw"},"source":["## 3. Inference on New Images with IoU Evaluation"]},{"cell_type":"markdown","metadata":{"id":"bjA4hdimiYIw"},"source":["### Configuration\n","\n","Define input/output paths and image processing parameters."]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k7dvDPHHiYIw","executionInfo":{"status":"ok","timestamp":1770565134645,"user_tz":-60,"elapsed":452,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}},"outputId":"80a4f91f-cccd-4c02-8691-140ead67e13a"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ Configuration complete\n"]}],"source":["# Input/Output paths\n","input_folder = '/content/drive/My Drive/Detectron2_Organoid_FineTuning/03_Data/Evaluation_Test/Inputs'\n","output_folder = '/content/drive/My Drive/Detectron2_Organoid_FineTuning/03_Data/Evaluation_Test/Masks_Output'\n","mask_folder = '/content/drive/My Drive/Detectron2_Organoid_FineTuning/03_Data/Evaluation_Test/Ground_Truth'\n","visual_output_folder = '/content/drive/My Drive/Detectron2_Organoid_FineTuning/03_Data/Evaluation_Test/Visual_Results'\n","excel_path = '/content/drive/My Drive/Detectron2_Organoid_FineTuning/04_Metrics_and_Results/IoU_Scores.xlsx'\n","\n","# Image resize parameters\n","max_width = 520\n","max_height = 693\n","\n","# Create output directories\n","for folder in [output_folder, visual_output_folder]:\n","    os.makedirs(folder, exist_ok=True)\n","\n","print(\"✓ Configuration complete\")"]},{"cell_type":"markdown","metadata":{"id":"6E0nDm-tiYIw"},"source":["### IoU Calculation Function"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"zJZJBT90iYIw","executionInfo":{"status":"ok","timestamp":1770565134647,"user_tz":-60,"elapsed":1,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}}},"outputs":[],"source":["def calculate_iou(pred_mask, true_mask):\n","    \"\"\"\n","    Calculate Intersection over Union (IoU) between predicted and ground truth masks.\n","\n","    Args:\n","        pred_mask: Predicted binary mask\n","        true_mask: Ground truth binary mask\n","\n","    Returns:\n","        IoU score (float between 0 and 1)\n","    \"\"\"\n","    pred_mask = pred_mask.astype(bool)\n","    true_mask = true_mask.astype(bool)\n","\n","    intersection = np.logical_and(pred_mask, true_mask).sum()\n","    union = np.logical_or(pred_mask, true_mask).sum()\n","\n","    if union == 0:\n","        return 0.0\n","\n","    return intersection / union"]},{"cell_type":"markdown","metadata":{"id":"19v7d-BUiYIw"},"source":["### Process Images and Calculate IoU"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4ZaD5ItuiYIx","executionInfo":{"status":"ok","timestamp":1770565147445,"user_tz":-60,"elapsed":12797,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}},"outputId":"85a6c453-3ec4-4c75-bc59-6f32d1911a6e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 6 images to process\n","\n"]},{"output_type":"stream","name":"stderr","text":["\rProcessing images:   0%|          | 0/6 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/functional.py:505: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /pytorch/aten/src/ATen/native/TensorShape.cpp:4317.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","W0208 15:38:56.707000 220 torch/fx/_symbolic_trace.py:52] is_fx_tracing will return true for both fx.symbolic_trace and torch.export. Please use is_fx_tracing_symbolic_tracing() for specifically fx.symbolic_trace or torch.compiler.is_compiling() for specifically torch.export/compile.\n","Processing images: 100%|██████████| 6/6 [00:12<00:00,  2.08s/it]"]},{"output_type":"stream","name":"stdout","text":["\n","✓ Processing complete!\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import pandas as pd\n","\n","# Initialize results storage\n","results = []\n","\n","# Get list of images to process\n","image_files = [f for f in os.listdir(input_folder) if f.lower().endswith(('.jpg', '.jpeg'))]\n","\n","print(f\"Found {len(image_files)} images to process\\n\")\n","\n","# Process each image\n","for filename in tqdm(image_files, desc=\"Processing images\"):\n","    # Define paths\n","    input_path = os.path.join(input_folder, filename)\n","    output_path = os.path.join(output_folder, os.path.splitext(filename)[0] + \".jpg\")\n","    mask_path = os.path.join(mask_folder, os.path.splitext(filename)[0] + \".jpg\")\n","    visual_path = os.path.join(visual_output_folder, filename)\n","\n","    # Skip if ground truth mask doesn't exist\n","    if not os.path.exists(mask_path):\n","        continue\n","\n","    # Read and resize input image\n","    im = cv2.imread(input_path)\n","    if im is None:\n","        continue\n","\n","    height, width = im.shape[:2]\n","    ratio = min(max_width / width, max_height / height)\n","    new_width, new_height = int(width * ratio), int(height * ratio)\n","    im = cv2.resize(im, (new_width, new_height))\n","\n","    # Run prediction\n","    outputs = predictor(im)\n","\n","    # Save visualization with predictions\n","    v = Visualizer(im[:, :, ::-1],\n","                   metadata=MetadataCatalog.get(cfg.DATASETS.TRAIN[0]),\n","                   scale=1.0)\n","    out_visual = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","    cv2.imwrite(visual_path, out_visual.get_image()[:, :, ::-1])\n","\n","    # Load and process ground truth mask\n","    true_mask_img = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n","    true_mask_img = cv2.resize(true_mask_img, (new_width, new_height), interpolation=cv2.INTER_NEAREST)\n","    true_mask_binary = (true_mask_img > 128).astype(np.uint8)\n","\n","    # Extract predicted mask\n","    pred_mask_binary = np.zeros((new_height, new_width), dtype=np.uint8)\n","\n","    if len(outputs[\"instances\"]) > 0:\n","        masks = outputs[\"instances\"].pred_masks.cpu().numpy()\n","        scores = outputs[\"instances\"].scores.cpu().numpy()\n","        # Select mask with highest confidence score\n","        max_score_idx = np.argmax(scores)\n","        pred_mask_binary = masks[max_score_idx].astype(np.uint8)\n","\n","    # Save predicted mask as image\n","    mask_image = np.ones((new_height, new_width, 3), dtype=np.uint8) * 255\n","    mask_image[pred_mask_binary == 0] = 1\n","    cv2.imwrite(output_path, mask_image)\n","\n","    # Calculate IoU\n","    iou_score = calculate_iou(pred_mask_binary, true_mask_binary)\n","\n","    # Store results\n","    results.append({\n","        'Image': os.path.splitext(filename)[0],\n","        'IoU Score': iou_score\n","    })\n","\n","print(\"\\n✓ Processing complete!\")"]},{"cell_type":"markdown","metadata":{"id":"f23kLI8MiYIx"},"source":["### Save Results and Display Summary"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"KC-Ai6y4iYIx","executionInfo":{"status":"ok","timestamp":1770565147886,"user_tz":-60,"elapsed":440,"user":{"displayName":"Axel Fontanier","userId":"07500030682246637610"}},"outputId":"a01ac0f3-186c-4ada-c086-13851a9ce81d"},"outputs":[{"output_type":"stream","name":"stdout","text":["✓ IoU scores saved to: /content/drive/My Drive/Detectron2_Organoid_FineTuning/04_Metrics_and_Results/IoU_Scores.xlsx\n","✓ Visual outputs saved to: /content/drive/My Drive/Detectron2_Organoid_FineTuning/03_Data/Evaluation_Test/Visual_Results\n","✓ Predicted masks saved to: /content/drive/My Drive/Detectron2_Organoid_FineTuning/03_Data/Evaluation_Test/Masks_Output\n","\n","=== Results Summary ===\n","Total images processed: 6\n","\n","IoU Score Statistics:\n","count    6.000000\n","mean     0.833813\n","std      0.154378\n","min      0.532003\n","25%      0.834340\n","50%      0.889505\n","75%      0.915649\n","max      0.951553\n","Name: IoU Score, dtype: float64\n","\n","=== Sample Results ===\n"]},{"output_type":"display_data","data":{"text/plain":["  Image  IoU Score\n","0   999   0.951553\n","1  1089   0.532003\n","2   994   0.867350\n","3  1029   0.916978\n","4   997   0.823336\n","5   987   0.911660"],"text/html":["\n","  <div id=\"df-07cbb471-ddf6-43f8-9a74-9a7bae05d1b5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image</th>\n","      <th>IoU Score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>999</td>\n","      <td>0.951553</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1089</td>\n","      <td>0.532003</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>994</td>\n","      <td>0.867350</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1029</td>\n","      <td>0.916978</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>997</td>\n","      <td>0.823336</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>987</td>\n","      <td>0.911660</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-07cbb471-ddf6-43f8-9a74-9a7bae05d1b5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-07cbb471-ddf6-43f8-9a74-9a7bae05d1b5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-07cbb471-ddf6-43f8-9a74-9a7bae05d1b5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"print(\\\"\\\\n\\u2713 Processing complete!\\\")\",\n  \"rows\": 6,\n  \"fields\": [\n    {\n      \"column\": \"Image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"999\",\n          \"1089\",\n          \"987\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IoU Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1543782435815949,\n        \"min\": 0.5320028884658308,\n        \"max\": 0.9515532544378699,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          0.9515532544378699,\n          0.5320028884658308,\n          0.9116600943323282\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","✓ Processing complete!\n"]}],"source":["# Save results to Excel\n","if results:\n","    df = pd.DataFrame(results)\n","    df.to_excel(excel_path, index=False)\n","\n","    print(f\"✓ IoU scores saved to: {excel_path}\")\n","    print(f\"✓ Visual outputs saved to: {visual_output_folder}\")\n","    print(f\"✓ Predicted masks saved to: {output_folder}\")\n","\n","    # Display summary statistics\n","    print(\"\\n=== Results Summary ===\")\n","    print(f\"Total images processed: {len(df)}\")\n","    print(f\"\\nIoU Score Statistics:\")\n","    print(df['IoU Score'].describe())\n","\n","    # Display first few results\n","    print(\"\\n=== Sample Results ===\")\n","    display(df.head(10))\n","else:\n","    print(\"No results to save.\")\n","\n","print(\"\\n✓ Processing complete!\")"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
